{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49bf96f4-a485-4793-943c-07cb77ad82c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_libs import retrievePytorchDetectionLibs\n",
    "retrievePytorchDetectionLibs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95a3e71d-3455-405b-974f-f0d980e4b35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference_training import Configuration, ImageDataset\n",
    "from inference_training import initCudaEnvironment, createTransforms\n",
    "from inference_training import drawImageAndFeatureMasks\n",
    "from inference_training import exportOnnxModel, writeONNXMeta, loadONNX\n",
    "from inference_training import trainModel, saveModel, loadModel\n",
    "from inference_training import createModelInstance, testInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "271a4c11-5b60-4f45-a504-8be8e706018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "initCudaEnvironment(numCudaDevices=1,\n",
    "                    visibleCudaDevices=\"0\",\n",
    "                    clearCudaDeviceCount=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21550852-e9f6-4f2d-98e8-e2d46365b967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Version: 20250121\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '<PATH TO TRAIN FILES>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 42\u001b[0m\n\u001b[1;32m     37\u001b[0m config\u001b[38;5;241m.\u001b[39msetOnnxMetaData(scoreThreshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m     38\u001b[0m                        maskThreshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,\n\u001b[1;32m     39\u001b[0m                        strideFraction\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     41\u001b[0m config\u001b[38;5;241m.\u001b[39msetTensorInfo(tensorName\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_A:RGB_normalized\u001b[39m\u001b[38;5;124m'\u001b[39m, batchAmount\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m trainingDataset \u001b[38;5;241m=\u001b[39m ImageDataset(config, \u001b[38;5;28;01mTrue\u001b[39;00m, createTransforms(\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m     43\u001b[0m testDataset \u001b[38;5;241m=\u001b[39m ImageDataset(config, \u001b[38;5;28;01mFalse\u001b[39;00m, createTransforms(\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Image count: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(trainingDataset\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m()))\n",
      "File \u001b[0;32m~/git/tygronsdk/sdktygron/src/py/inference_training.py:254\u001b[0m, in \u001b[0;36mImageDataset.__init__\u001b[0;34m(self, configuration, isTraining, transforms)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfiguration \u001b[38;5;241m=\u001b[39m configuration\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;241m=\u001b[39m transforms\n\u001b[0;32m--> 254\u001b[0m files \u001b[38;5;241m=\u001b[39m configuration\u001b[38;5;241m.\u001b[39mgetFiles(isTraining)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages \u001b[38;5;241m=\u001b[39m [f\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files \u001b[38;5;28;01mif\u001b[39;00m configuration\u001b[38;5;241m.\u001b[39mimagePredicate(f\u001b[38;5;241m.\u001b[39mpath)]\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasks \u001b[38;5;241m=\u001b[39m [f\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files \u001b[38;5;28;01mif\u001b[39;00m configuration\u001b[38;5;241m.\u001b[39mmaskPredicate(f\u001b[38;5;241m.\u001b[39mpath)]\n",
      "File \u001b[0;32m~/git/tygronsdk/sdktygron/src/py/inference_training.py:244\u001b[0m, in \u001b[0;36mConfiguration.getFiles\u001b[0;34m(self, train)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetFiles\u001b[39m(\u001b[38;5;28mself\u001b[39m, train: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    243\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetTrainPath() \u001b[38;5;28;01mif\u001b[39;00m train \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetTestPath()\n\u001b[0;32m--> 244\u001b[0m     files \u001b[38;5;241m=\u001b[39m listFilesRecursive(path)\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(files, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m f: f\u001b[38;5;241m.\u001b[39mpath)\n",
      "File \u001b[0;32m~/git/tygronsdk/sdktygron/src/py/inference_training.py:361\u001b[0m, in \u001b[0;36mlistFilesRecursive\u001b[0;34m(path, files)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlistFilesRecursive\u001b[39m(path, files\u001b[38;5;241m=\u001b[39m[]):\n\u001b[0;32m--> 361\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m os\u001b[38;5;241m.\u001b[39mscandir(path) \u001b[38;5;28;01mas\u001b[39;00m entries:\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m entries:\n\u001b[1;32m    363\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_file():\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '<PATH TO TRAIN FILES>'"
     ]
    }
   ],
   "source": [
    "# train on the GPU or on the CPU, if a GPU is not available\n",
    "config = Configuration()\n",
    "print(\"Device: \" + str(config.device))\n",
    "\n",
    "trainDirectory = \"<PATH TO TRAIN FILES>\"\n",
    "testDirectory = \"<PATH TO TEST FILES>\"\n",
    "\n",
    "config.setDatasetPaths(trainPath=trainDirectory, testPath=testDirectory)\n",
    "config.setFilePrefix(\"foliage_\")\n",
    "config.setModelName(\"foliage\")\n",
    "config.setInputSizes(inputWidth=250, inputHeight=250)\n",
    "config.setInputCellSize(cellSizeM=0.25, minCellSizeM=0.1, maxCellSizeM=0.5)\n",
    "\n",
    "config.setVersion(20250121)\n",
    "\n",
    "print(\"Version: \" + str(config.version))\n",
    "\n",
    "config.setModelInfo(channels=3, numClasses=8+1,  # (1 + background)\n",
    "                    bboxOverlap=True, bboxPerImage=250, reuseModel=False)\n",
    "config.setEpochs(1)\n",
    "\n",
    "description = \"Inference model to detect deciduous trees, pine trees, \"\\\n",
    "    \"heather, hedges,plants, reed, shrubbery, flowbeds. \" \\\n",
    "    \"Additionally regions of decidious trees without leaves can be detected.\"\n",
    "config.setOnnxInfo(producer=\"Tygron\", description=description)\n",
    "\n",
    "config.addLegendEntry(\"Background\", 0, \"#00000000\")\n",
    "config.addLegendEntry(\"Deciduous Tree\", 1, \"#00ffbf\")\n",
    "config.addLegendEntry(\"Pine Tree\", 2, \"#12d900\")\n",
    "config.addLegendEntry(\"Heather\", 3, \"#f3a6b2\")\n",
    "config.addLegendEntry(\"Hedge\", 4, \"#8d5a99\")\n",
    "config.addLegendEntry(\"Shrubbery\", 5, \"#e80004\")\n",
    "config.addLegendEntry(\"Reed\", 6, \"#f8ff20\")\n",
    "config.addLegendEntry(\"Flowerbed\", 7, \"#b7484b\")\n",
    "config.addLegendEntry(\"Deciduous Tree (Leafless)\", 8, \"#e6994d\")\n",
    "\n",
    "config.setOnnxMetaData(scoreThreshold=0.2,\n",
    "                       maskThreshold=0.3,\n",
    "                       strideFraction=0.5)\n",
    "\n",
    "config.setTensorInfo(tensorName='input_A:RGB_normalized', batchAmount=1)\n",
    "trainingDataset = ImageDataset(config, True, createTransforms(True))\n",
    "testDataset = ImageDataset(config, False, createTransforms(False))\n",
    "\n",
    "print(\"Train Image count: \"+str(trainingDataset.__len__()))\n",
    "print(\"Test Image count: \"+str(testDataset.__len__()))\n",
    "\n",
    "if not trainingDataset.validateFiles(False):\n",
    "    print(\"Inconsistent training dataset \")\n",
    "    trainingDataset.validateFiles(True)\n",
    "\n",
    "if not testDataset.validateFiles(False):\n",
    "    print(\"Inconsistent test dataset \")\n",
    "    testDataset.validateFiles(True)\n",
    "\n",
    "print(\"Pytorch model name \" + config.getPytorchModelFileName())\n",
    "print(\"Onnx file name \" + config.getOnnxFileName())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09aea7a-9a3a-4ec4-a161-55173a86cdfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imageNumber = 5\n",
    "print(trainingDataset.getLabelList(imageNumber))\n",
    "drawImageAndFeatureMasks(config, trainingDataset, imageNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f639e7-aa3c-4001-82b5-fec4fe86f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadExistingModel = False\n",
    "\n",
    "if loadExistingModel:\n",
    "    model = createModelInstance(config)\n",
    "    loadModel(config, model, path=config.getPytorchModelFileName())\n",
    "\n",
    "else:\n",
    "    model = trainModel(config, trainingDataset, testDataset)\n",
    "    saveModel(config, model, path=config.getPytorchModelFileName())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042aede8-7ac6-45be-a82d-31c1852f1e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "testPrediction = testInference(config, model=model,\n",
    "                               dataset=testDataset, imageNumber=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8ca3f6-abbf-408b-afb3-91084272533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exportOnnxModel(config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701edd17-f779-4c1a-9c9e-4f50dbbbabca",
   "metadata": {},
   "outputs": [],
   "source": [
    "writeONNXMeta(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fe11d4-d9b7-4ed1-9473-1379cb506e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = loadONNX(config)\n",
    "print(f\"metadata_props={onnx_model.metadata_props}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
